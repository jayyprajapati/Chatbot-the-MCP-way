Metadata-Version: 2.4
Name: app
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.31.0
Requires-Dist: mcp[cli]>=1.8.0
Requires-Dist: prompt-toolkit>=3.0.51
Requires-Dist: python-dotenv>=1.1.0

# MCP Chat

MCP Chat is a command-line interface application that enables interactive chat capabilities with AI models using Llama (via Ollama). The application supports document retrieval, command-based prompts, and extensible tool integrations via the MCP (Model Control Protocol) architecture.

## Prerequisites

- Python 3.10+
- Ollama installed and running locally (for Llama inference)
- A Llama model downloaded in Ollama

## Setup

### Step 0: Install and Start Ollama

1. Download and install [Ollama](https://ollama.ai/)
2. Pull a Llama model:
   ```bash
   ollama pull llama2
   ```
3. Start the Ollama server:
   ```bash
   ollama serve
   ```
   The server will run on `http://localhost:11434` by default.

### Step 1: Configure the environment variables

1. Create or edit the `.env` file in the project root and verify that the following variables are set correctly:

```
LLAMA_MODEL="llama2"  # Change to your downloaded model if different
OLLAMA_BASE_URL="http://localhost:11434"  # Ollama server URL
```

### Step 2: Install dependencies

#### Option 1: Setup with uv (Recommended)

[uv](https://github.com/astral-sh/uv) is a fast Python package installer and resolver.

1. Install uv, if not already installed:

```bash
pip install uv
```

2. Create and activate a virtual environment:

```bash
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:

```bash
uv pip install -e .
```

4. Run the project

```bash
uv run main.py
```

#### Option 2: Setup without uv

1. Create and activate a virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

2. Install dependencies:

```bash
pip install requests python-dotenv prompt-toolkit "mcp[cli]==1.8.0"
```

3. Run the project

```bash
python main.py
```

## Usage

### Basic Interaction

Simply type your message and press Enter to chat with the model.

### Document Retrieval

Use the @ symbol followed by a document ID to include document content in your query:

```
> Tell me about @deposition.md
```

### Commands

Use the / prefix to execute commands defined in the MCP server:

```
> /summarize deposition.md
```

Commands will auto-complete when you press Tab.

## Development

### Adding New Documents

Edit the `mcp_server.py` file to add new documents to the `docs` dictionary.

### Implementing MCP Features

To fully implement the MCP features:

1. Complete the TODOs in `mcp_server.py`
2. Implement the missing functionality in `mcp_client.py`

### Linting and Typing Check

There are no lint or type checks implemented.
